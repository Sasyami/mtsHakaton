{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import transliterate\n",
    "from wordcloud import WordCloud\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from deep_translator import GoogleTranslator\n",
    "import langdetect\n",
    "import re\n",
    "\n",
    "\n",
    "model = spacy.load(\"ru_core_news_lg\")\n",
    "data = pd.read_csv('responses.csv', sep=';', header=None, names=['responses'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(text):\n",
    "    try:\n",
    "        return 'en' if langdetect.detect(text) == 'en' else 'ru'\n",
    "    except: return 'ru'\n",
    "\n",
    "def translate_text(text):\n",
    "    return GoogleTranslator(source='en', target='ru').translate(text)\n",
    "\n",
    "def fix_translit(text):\n",
    "    return transliterate.translit(text, 'ru')\n",
    "\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\sа-яА-ЯёЁ]+', '', text)\n",
    "\n",
    "def extract_key_phrase(phrase):\n",
    "    doc = model(phrase)\n",
    "    if len(phrase) > 4:\n",
    "        root = [t for t in doc if t.dep_ == \"ROOT\"][0]\n",
    "        result = root.text\n",
    "        if root.pos_ == \"NOUN\":\n",
    "            adj = [t for t in doc if t.dep_ == \"amod\" and t.head == root]\n",
    "            if adj: result = f\"{root.text} {adj[0].text}\"\n",
    "        elif root.pos_ == \"VERB\":\n",
    "            adv = [t for t in doc if t.dep_ == \"advmod\" and t.head == root]\n",
    "            if adv: result = f\"{root.text} {adv[0].text}\"\n",
    "        return result\n",
    "    return phrase\n",
    "\n",
    "data['translated'] = data['responses'].apply(lambda x: translate_text(x) if detect_lang(x) == 'en' else x)\n",
    "data['translated'] = data['translated'].apply(fix_translit).apply(clean_text)\n",
    "data['key_phrases'] = data['translated'].apply(extract_key_phrase)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_cache = {}\n",
    "def get_vector(word):\n",
    "    if word not in vec_cache:\n",
    "        vec_cache[word] = model(\" \".join([t.lemma_ for t in model(word)])).vector\n",
    "    return vec_cache[word]\n",
    "\n",
    "def similarity(a, b):\n",
    "    v1, v2 = get_vector(a), get_vector(b)\n",
    "    return np.dot(v1, v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n",
    "\n",
    "words = list(data['key_phrases'])\n",
    "groups = defaultdict(list)\n",
    "threshold = 0.6\n",
    "\n",
    "i = 0\n",
    "while i < len(words):\n",
    "    current = words[i]\n",
    "    if any(current in g for g in groups.values()):\n",
    "        i += 1\n",
    "        continue\n",
    "        \n",
    "    groups[current] = [current]\n",
    "    similar = [w for w in words if similarity(current, w) > threshold]\n",
    "    \n",
    "    for word in similar:\n",
    "        if word in words:\n",
    "            groups[current].append(word)\n",
    "            words.remove(word)\n",
    "\n",
    "with open('synonyms.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(dict(groups), f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация облака слов\n",
    "freq = {k: len(v) for k, v in groups.items()}\n",
    "cloud = WordCloud(width=800, height=500, background_color=\"white\").generate_from_frequencies(freq)\n",
    "\n",
    "plt.figure(figsize=(16,12))\n",
    "plt.imshow(cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig('wordcloud.png', bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
